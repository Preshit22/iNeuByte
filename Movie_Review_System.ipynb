{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAhSmNcfskCg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "data_lines = []\n",
        "\n",
        "with open(\"/content/IMDB Dataset.csv\", \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        data_lines.append(line)\n",
        "\n",
        "\n",
        "csv_content = ''.join(data_lines)\n",
        "\n",
        "try:\n",
        "    imdb = pd.read_csv(io.StringIO(csv_content))\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"ParserError: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ueVXinLWMeiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb.head()"
      ],
      "metadata": {
        "id": "TuU39qj8Mqqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of rows: \", imdb.shape[0])\n",
        "print(\"Nummer of columns: \", imdb.shape[1])"
      ],
      "metadata": {
        "id": "rsskwvaYypSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb.info()"
      ],
      "metadata": {
        "id": "yYVEhHCMypVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb.sentiment.value_counts()"
      ],
      "metadata": {
        "id": "ATFuRjqzypYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb['review'][1]\n"
      ],
      "metadata": {
        "id": "8EtgJsnCypbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "cleantext = BeautifulSoup(imdb[\"review\"][1], 'lxml').text\n",
        "cleantext"
      ],
      "metadata": {
        "id": "Vm_nIPaA18i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "cleantext = re.sub(r'[^\\w\\s]', '', cleantext)\n",
        "cleantext"
      ],
      "metadata": {
        "id": "h3Hfvlp818lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "JxZJgw1C18oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords.words('english')"
      ],
      "metadata": {
        "id": "sjU-9O_m2A-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = cleantext.lower().split()\n",
        "stopword = set(stopwords.words('english'))\n",
        "token_list = [ word for word in token if word.lower() not in stopword ]"
      ],
      "metadata": {
        "id": "mY4zGAXv2A6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\" \".join(token_list)"
      ],
      "metadata": {
        "id": "alA5JJ3V2Azi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "-WGQy-O_2MYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "QHyB0iN12NH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "2Vgdsjwj2NER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "2I03PO5D2NBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\" \".join(token_list))"
      ],
      "metadata": {
        "id": "gXUFOOmH2M-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb.keys()"
      ],
      "metadata": {
        "id": "r7x03hkh2VHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def data_cleaner(imdb):\n",
        "    clean_data = []\n",
        "    for review in tqdm(imdb):\n",
        "        cleantext = BeautifulSoup(review, \"lxml\").text\n",
        "        cleantext = re.sub(r'[^\\w\\s]', '', cleantext)\n",
        "        cleantext = [ token for token in cleantext.lower().split() if token not in stopword ]\n",
        "        cleantext = lemmatizer.lemmatize(\" \".join(cleantext))\n",
        "        clean_data.append(cleantext.strip())\n",
        "    return clean_data"
      ],
      "metadata": {
        "id": "iMFIyheb2VFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data = data_cleaner(imdb.review.values)"
      ],
      "metadata": {
        "id": "4A8hhmkn2VCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data[0]"
      ],
      "metadata": {
        "id": "1KdAQ0Z22U_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(imdb, imdb.sentiment, test_size=0.2, random_state=42, stratify=imdb.sentiment)"
      ],
      "metadata": {
        "id": "WY0750hF2dJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "le_test = LabelEncoder()\n",
        "y_test = le_test.fit_transform(y_test)"
      ],
      "metadata": {
        "id": "Lt3nsrSG2dGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "rIjqMUlP2dBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data_train_data = data_cleaner(X_train.review.values)"
      ],
      "metadata": {
        "id": "I7nFSTnI2c-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['cleaned_text'] = clean_data_train_data\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "TQb49zTn2c7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data_test_data = data_cleaner(X_test.review.values)\n",
        "X_test['cleaned_text'] = clean_data_test_data\n",
        "X_test.head()"
      ],
      "metadata": {
        "id": "jwYvChQOc_gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "aIftz3Ny2m-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec = CountVectorizer()\n",
        "vec = vec.fit(X_train.cleaned_text)\n",
        "train_x_bow = vec.transform(X_train.cleaned_text)\n",
        "test_x_bow = vec.transform(X_test.cleaned_text)"
      ],
      "metadata": {
        "id": "Wa841Z5U2nDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x_bow.shape)\n",
        "print(test_x_bow.shape)"
      ],
      "metadata": {
        "id": "68avNo7m2wuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "zWnrU23Z2wrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MultinomialNB()"
      ],
      "metadata": {
        "id": "rFfGJVUV2woo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha_ranges = {\n",
        "    \"alpha\": [0.001, 0.01, 0.1, 1, 10.0, 100]\n",
        "}"
      ],
      "metadata": {
        "id": "qKh8R6kE2wlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(classifier, param_grid=alpha_ranges, scoring='accuracy', cv=3, return_train_score=True)\n",
        "grid_search.fit(train_x_bow, y_train)"
      ],
      "metadata": {
        "id": "nDSRDip823Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = [0.001, 0.01, 0.1, 1, 10.0, 100]\n",
        "train_acc = grid_search.cv_results_['mean_train_score']\n",
        "train_std = grid_search.cv_results_['std_train_score']\n",
        "\n",
        "test_acc = grid_search.cv_results_['mean_test_score']\n",
        "test_std = grid_search.cv_results_['std_test_score']"
      ],
      "metadata": {
        "id": "FThiYfqT23QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NxyN1ghj23NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(alpha, train_acc, label=\"Training Score\", color='b')\n",
        "plt.plot(alpha, test_acc, label=\"Cross Validation Score\", color='r')\n",
        "\n",
        "plt.title(\"Validation Curve with Naive Bayes Classifier\")\n",
        "plt.xlabel(\"Alpha\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "50OTvJpG23Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "QYH6tplw3Ag7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MultinomialNB(alpha=1)\n",
        "classifier.fit(train_x_bow, y_train)"
      ],
      "metadata": {
        "id": "Sb_ztwVr3CEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = classifier.predict(test_x_bow)"
      ],
      "metadata": {
        "id": "0IK8bPTv3CBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy is \", accuracy_score(y_test, predict))"
      ],
      "metadata": {
        "id": "2SdBprn93B-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(\"Accuracy is \", classification_report(y_test, predict))"
      ],
      "metadata": {
        "id": "DU5rue4-3B7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"I liked the movie. It was great\"]\n",
        "text_vec = vec.transform(text)\n",
        "classifier.predict(text_vec)"
      ],
      "metadata": {
        "id": "JauKjlsc3H4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le.inverse_transform([1])"
      ],
      "metadata": {
        "id": "41eQecm_3JXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Movie was worse\"]\n",
        "text_vec = vec.transform(text)\n",
        "classifier.predict(text_vec)"
      ],
      "metadata": {
        "id": "PbSWZH0r3JUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le.inverse_transform([0])"
      ],
      "metadata": {
        "id": "v0NDPuPi3LFQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}